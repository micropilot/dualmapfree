run_name: auto

# Architecture
encoder_type: BottleneckMLP/B_6-Wi_1024
decoder_type: BottleneckMLP/B_6-Wi_1024

# Quantizer
codebook_size: 1024
latent_dim: 1024
num_codebooks: 8
quantizer_type: memcodes

# Losses
loss_fn: smooth_l1

# Train
dtype: bf16 # fp32, fp16 or bf16
epochs: 15
opt: adamw
opt_betas: [0.9, 0.99]
blr: 0.0001 # base_lr = 1e-4, lr = base_lr * batch_size / 256
warmup_lr: 0.000001 # 1e-6
min_lr: 0.
warmup_epochs: 1
batch_size: 64 # per GPU
clip_grad: 1.0
model_ema: True
model_ema_decay: 0.99
model_ema_update_freq: 1
find_unused_params: True
save_ckpt_freq: 1

# Eval
step_eval: True
epoch_eval: False
eval_freq: 5000
eval_metrics_freq: 5000
eval_image_log_freq: 5000
num_eval_metrics_samples: null # Number of samples to use for evaluating image metrics during training.
num_logged_images: null

# Data
domain: human_poses
imagenet_default_mean_and_std: True
min_crop_scale: 0.2
data_path: '/path/to/dataset' # Change me
eval_data_path: '/path/to/eval_dataset' # Change me

# Wandb
log_wandb: False # Set to True to log to Weights & Biases
wandb_project: '4m-tokenizers'
wandb_entity: null # Change if needed
wandb_run_name: auto
output_dir: 'output/auto'