run_name: auto

# Architecture
encoder_type: vit_b_enc
decoder_type: vit_b_dec
input_size_min: 224
input_size_max: 448
resolution_step: 14
patch_size: 14
post_mlp: True # tanh MLP before quantizer

# Start from base-resolution checkpoint
full_ckpt: '/path/to/pretrained_weights' # Change me

# Quantizer
codebook_size: 8192
latent_dim: 32
norm_codes: True
quantizer_type: lucid
coef_ema_dead_code: 32.0
code_replacement_policy: batch_random
commitment_weight: 1.0
quantizer_ema_decay: 0.99
kmeans_init: False

# Losses
loss_fn: smooth_l1
codebook_weight: 1.0

# Train
dtype: bf16 # fp32, fp16 or bf16
epochs: 1
opt: adamw
opt_betas: [0.9, 0.99]
blr: 0.00005 # base_lr = 5e-5, lr = base_lr * batch_size / 256
warmup_lr: 0.000001 # 1e-6
min_lr: 0.
warmup_epochs: -1
warmup_steps: 5000
batch_size: 16 # per GPU
hflip: 0.5
clip_grad: 1.0
model_ema: True
model_ema_decay: 0.99
model_ema_update_freq: 1
find_unused_params: True
save_ckpt_freq: 1

# Eval
step_eval: True
epoch_eval: False
eval_freq: 5000
eval_metrics_freq: 5000
eval_image_log_freq: 5000
num_eval_metrics_samples: 50000 # Number of samples to use for evaluating image metrics during training.
num_logged_images: 100
input_size_eval: 256

# Data
domain: ImageBind-H14
imagenet_default_mean_and_std: True
min_crop_scale: 0.2
data_path: '/path/to/dataset' # Change me
eval_data_path: '/path/to/eval_dataset' # Change me

# Wandb
log_wandb: False # Set to True to log to Weights & Biases
wandb_project: '4m-tokenizers'
wandb_entity: null # Change if needed
wandb_run_name: auto
output_dir: 'output/auto'